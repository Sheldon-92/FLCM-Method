# Story 2.0-1.6: Migration Analytics and Monitoring

## Status
Draft

## Story
**As a** system operator,  
**I want** comprehensive metrics on migration progress,  
**so that** we can ensure smooth transition.

## Acceptance Criteria
1. Dashboard shows usage split between 1.0 and 2.0
2. Error rates tracked separately per version
3. Performance comparison metrics available
4. User satisfaction tracked for both versions
5. Automated alerts for migration issues

## Tasks / Subtasks
- [ ] Task 1: Build analytics dashboard (AC: 1)
  - [ ] Subtask 1.1: Design dashboard UI layout
  - [ ] Subtask 1.2: Implement real-time data visualization
  - [ ] Subtask 1.3: Create version comparison views
  - [ ] Subtask 1.4: Add export functionality for reports

- [ ] Task 2: Implement error tracking (AC: 2)
  - [ ] Subtask 2.1: Create error categorization system
  - [ ] Subtask 2.2: Build version-specific error collectors
  - [ ] Subtask 2.3: Implement error trend analysis
  - [ ] Subtask 2.4: Add error correlation detection

- [ ] Task 3: Create performance monitoring (AC: 3)
  - [ ] Subtask 3.1: Instrument key operations for both versions
  - [ ] Subtask 3.2: Build performance comparison engine
  - [ ] Subtask 3.3: Implement latency tracking
  - [ ] Subtask 3.4: Add resource usage monitoring

- [ ] Task 4: Build satisfaction tracking (AC: 4)
  - [ ] Subtask 4.1: Implement feedback collection system
  - [ ] Subtask 4.2: Create NPS survey integration
  - [ ] Subtask 4.3: Build sentiment analysis for feedback
  - [ ] Subtask 4.4: Add satisfaction trend visualization

- [ ] Task 5: Implement alerting system (AC: 5)
  - [ ] Subtask 5.1: Define alert threshold configurations
  - [ ] Subtask 5.2: Create multi-channel alert delivery
  - [ ] Subtask 5.3: Build alert escalation logic
  - [ ] Subtask 5.4: Implement alert suppression rules

- [ ] Task 6: Write comprehensive tests
  - [ ] Subtask 6.1: Unit tests for metric collectors
  - [ ] Subtask 6.2: Integration tests for dashboard
  - [ ] Subtask 6.3: Load tests for metric ingestion
  - [ ] Subtask 6.4: Alert system reliability tests

## Dev Notes

### Analytics Architecture
```python
# flcm-core/analytics/migration-monitor.py
class MigrationMonitor:
    def __init__(self):
        self.metrics_store = TimeSeriesDB()
        self.dashboard = DashboardService()
        self.alerting = AlertingEngine()
        self.collectors = {
            'usage': UsageCollector(),
            'errors': ErrorCollector(),
            'performance': PerformanceCollector(),
            'satisfaction': SatisfactionCollector()
        }
    
    def collect_metrics(self):
        """Collect metrics from all sources"""
        for name, collector in self.collectors.items():
            metrics = collector.collect()
            self.metrics_store.write(name, metrics)
            self.evaluate_alerts(name, metrics)
```

### Dashboard Configuration
```yaml
# dashboard-config.yaml
dashboard:
  refresh_interval: 5000  # 5 seconds
  
  panels:
    - id: version_split
      type: pie_chart
      title: "Version Usage Distribution"
      metrics:
        - query: "sum(usage_by_version)"
        - group_by: "version"
      
    - id: error_comparison
      type: time_series
      title: "Error Rates by Version"
      metrics:
        - query: "rate(errors{version='1.0'}[5m])"
        - query: "rate(errors{version='2.0'}[5m])"
      
    - id: performance_heatmap
      type: heatmap
      title: "Response Time Distribution"
      metrics:
        - query: "histogram_quantile(0.95, response_time)"
        - facet_by: ["version", "operation"]
    
    - id: migration_progress
      type: gauge
      title: "2.0 Adoption Rate"
      metrics:
        - query: "users_on_v2 / total_users * 100"
```

### Metric Collection Implementation
```python
class UsageCollector:
    def __init__(self):
        self.usage_data = defaultdict(lambda: {
            'requests': 0,
            'unique_users': set(),
            'operations': defaultdict(int)
        })
    
    def track_request(self, version: str, user_id: str, operation: str):
        """Track individual request"""
        data = self.usage_data[version]
        data['requests'] += 1
        data['unique_users'].add(user_id)
        data['operations'][operation] += 1
    
    def collect(self) -> dict:
        """Aggregate and return metrics"""
        metrics = {}
        for version, data in self.usage_data.items():
            metrics[f'usage.{version}.requests'] = data['requests']
            metrics[f'usage.{version}.users'] = len(data['unique_users'])
            
            # Operation breakdown
            for op, count in data['operations'].items():
                metrics[f'usage.{version}.op.{op}'] = count
        
        # Calculate adoption rate
        v1_users = len(self.usage_data['1.0']['unique_users'])
        v2_users = len(self.usage_data['2.0']['unique_users'])
        if v1_users + v2_users > 0:
            metrics['adoption_rate'] = v2_users / (v1_users + v2_users)
        
        return metrics
```

### Error Tracking System
```python
class ErrorCollector:
    def __init__(self):
        self.errors = defaultdict(list)
        self.error_categories = {
            'syntax': r'Syntax|Parse|Invalid',
            'runtime': r'Runtime|Exception|Error',
            'timeout': r'Timeout|Deadline',
            'resource': r'Memory|Disk|Resource',
            'network': r'Network|Connection|Socket'
        }
    
    def track_error(self, version: str, error: Exception, context: dict):
        """Track error occurrence"""
        error_data = {
            'timestamp': time.time(),
            'type': type(error).__name__,
            'message': str(error),
            'category': self.categorize_error(error),
            'context': context,
            'stack_trace': traceback.format_exc()
        }
        
        self.errors[version].append(error_data)
        
        # Check for error patterns
        self.detect_error_patterns(version)
    
    def categorize_error(self, error: Exception) -> str:
        """Categorize error type"""
        error_str = str(error)
        for category, pattern in self.error_categories.items():
            if re.search(pattern, error_str, re.IGNORECASE):
                return category
        return 'unknown'
    
    def detect_error_patterns(self, version: str):
        """Detect recurring error patterns"""
        recent_errors = self.errors[version][-100:]  # Last 100 errors
        
        # Group by error type
        error_groups = defaultdict(list)
        for error in recent_errors:
            key = f"{error['category']}:{error['type']}"
            error_groups[key].append(error)
        
        # Check for spikes
        for key, errors in error_groups.items():
            if len(errors) > 10:  # Threshold for pattern
                self.trigger_error_alert(version, key, errors)
```

### Performance Comparison
```python
class PerformanceCollector:
    def __init__(self):
        self.timings = defaultdict(list)
        self.resource_usage = defaultdict(list)
    
    def track_operation(self, version: str, operation: str, 
                       duration: float, memory_used: int):
        """Track operation performance"""
        self.timings[f"{version}:{operation}"].append(duration)
        self.resource_usage[f"{version}:{operation}"].append(memory_used)
    
    def collect(self) -> dict:
        """Calculate performance metrics"""
        metrics = {}
        
        # Calculate percentiles for each operation
        for key, durations in self.timings.items():
            version, operation = key.split(':')
            
            if durations:
                metrics[f'perf.{version}.{operation}.p50'] = np.percentile(durations, 50)
                metrics[f'perf.{version}.{operation}.p95'] = np.percentile(durations, 95)
                metrics[f'perf.{version}.{operation}.p99'] = np.percentile(durations, 99)
                metrics[f'perf.{version}.{operation}.avg'] = np.mean(durations)
        
        # Compare versions
        self.generate_comparison_metrics(metrics)
        
        return metrics
    
    def generate_comparison_metrics(self, metrics: dict):
        """Generate version comparison metrics"""
        operations = set()
        for key in metrics.keys():
            if 'perf.' in key:
                parts = key.split('.')
                if len(parts) >= 3:
                    operations.add(parts[2])
        
        for op in operations:
            v1_avg = metrics.get(f'perf.1.0.{op}.avg', 0)
            v2_avg = metrics.get(f'perf.2.0.{op}.avg', 0)
            
            if v1_avg > 0:
                improvement = ((v1_avg - v2_avg) / v1_avg) * 100
                metrics[f'perf.comparison.{op}.improvement'] = improvement
```

### User Satisfaction Tracking
```python
class SatisfactionCollector:
    def __init__(self):
        self.feedback = defaultdict(list)
        self.nps_scores = defaultdict(list)
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def collect_feedback(self, version: str, user_id: str, 
                        feedback_text: str, rating: int = None):
        """Collect user feedback"""
        feedback_data = {
            'timestamp': time.time(),
            'user_id': user_id,
            'text': feedback_text,
            'rating': rating,
            'sentiment': self.sentiment_analyzer.analyze(feedback_text)
        }
        
        self.feedback[version].append(feedback_data)
        
        if rating is not None:
            self.nps_scores[version].append(rating)
    
    def calculate_nps(self, version: str) -> float:
        """Calculate Net Promoter Score"""
        scores = self.nps_scores.get(version, [])
        if not scores:
            return 0
        
        promoters = sum(1 for s in scores if s >= 9)
        detractors = sum(1 for s in scores if s <= 6)
        
        return ((promoters - detractors) / len(scores)) * 100
    
    def get_sentiment_summary(self, version: str) -> dict:
        """Get sentiment analysis summary"""
        feedbacks = self.feedback.get(version, [])
        if not feedbacks:
            return {'positive': 0, 'neutral': 0, 'negative': 0}
        
        sentiments = [f['sentiment'] for f in feedbacks]
        return {
            'positive': sentiments.count('positive') / len(sentiments),
            'neutral': sentiments.count('neutral') / len(sentiments),
            'negative': sentiments.count('negative') / len(sentiments)
        }
```

### Alert Configuration
```yaml
# alerts.yaml
alerts:
  - name: high_error_rate
    condition: "rate(errors[5m]) > 0.05"
    severity: critical
    channels: ["slack", "email", "pagerduty"]
    
  - name: version_2_adoption_stalled
    condition: "delta(adoption_rate[1h]) < 0.001"
    severity: warning
    channels: ["slack", "email"]
    
  - name: performance_regression
    condition: "perf.comparison.*.improvement < -10"
    severity: warning
    channels: ["slack"]
    
  - name: user_satisfaction_drop
    condition: "nps_score < previous_nps_score - 10"
    severity: critical
    channels: ["slack", "email", "pagerduty"]
    
  - name: migration_rollback_triggered
    condition: "feature_flag.*.state == 'rolled_back'"
    severity: critical
    channels: ["slack", "email", "pagerduty"]
```

### Performance Requirements
- Metric collection overhead: <2% CPU
- Dashboard refresh: <2s
- Alert triggering: <30s from condition
- Data retention: 90 days high-resolution, 1 year aggregated

### Testing
- **Test Location**: `tests/analytics/`
- **Dashboard Tests**: `tests/analytics/dashboard/`
- **Alert Tests**: `tests/analytics/alerting/`
- **Load Tests**: Simulate 10k users, 100k requests/hour
- **Data Integrity**: Verify no metric loss under load

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-31 | 1.0 | Initial story creation | Bob (SM) |

## Dev Agent Record
*To be populated during implementation*

### Agent Model Used
*TBD*

### Debug Log References
*TBD*

### Completion Notes List
*TBD*

### File List
*TBD*

## QA Results
*To be populated during QA*